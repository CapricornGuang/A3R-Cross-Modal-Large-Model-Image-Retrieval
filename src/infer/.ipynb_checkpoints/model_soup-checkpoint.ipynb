{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0ae525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入CLIP\n",
    "import open_clip\n",
    "import torch\n",
    "# 使用 PyTorch 的工具方法来计算随机加权平均\n",
    "from torch.optim.swa_utils import AveragedModel\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58b3a943-6517-4484-b4bb-3d5942ed11a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting open_clip_torch\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ae/44/8b8f79c7174cdf119125ec056b2f5f01a3452efca40b385ad1f2c0cd2664/open_clip_torch-2.19.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/58/34/c57b951aecd0248845932c1cfc15721237c50e463f26b0536673bcb76f4f/huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /root/miniconda3/lib/python3.8/site-packages (from open_clip_torch) (4.65.0)\n",
      "Requirement already satisfied: torchvision in /root/miniconda3/lib/python3.8/site-packages (from open_clip_torch) (0.12.0+cu113)\n",
      "Collecting timm\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f6/c6/806d9b2fa95f418ad700dd206a935d5e8d7355505589dd13a70eb3a45048/timm-0.6.13-py3-none-any.whl (549 kB)\n",
      "\u001b[K     |████████████████████████████████| 549 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /root/miniconda3/lib/python3.8/site-packages (from open_clip_torch) (1.11.0+cu113)\n",
      "Collecting sentencepiece\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c9/58/4fbd3f33a38c9809fedf57bbef7e086b9909d6807148f35d68c0c90896d3/sentencepiece-0.1.99-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ftfy\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e1/1e/bf736f9576a8979752b826b75cbd83663ff86634ea3055a766e2d8ad3ee5/ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e0/7c/941e5c89bbbcd6ba460444c6ec029d54e7147741078f1c8300a8cbf8abb9/regex-2023.5.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "\u001b[K     |████████████████████████████████| 771 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4 in /root/miniconda3/lib/python3.8/site-packages (from open_clip_torch) (3.19.4)\n",
      "Requirement already satisfied: typing-extensions in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.9.0->open_clip_torch) (4.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /root/miniconda3/lib/python3.8/site-packages (from ftfy->open_clip_torch) (0.2.5)\n",
      "Requirement already satisfied: packaging>=20.9 in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub->open_clip_torch) (21.3)\n",
      "Collecting filelock\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ad/73/b094a662ae05cdc4ec95bc54e434e307986a5de5960166b8161b7c1373ee/filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub->open_clip_torch) (6.0)\n",
      "Collecting fsspec\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d6/30/db3078afe553e9a07c87534cbfb87a8c8ebb083fa0a8847ca5bdc86b51a7/fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub->open_clip_torch) (2.25.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /root/miniconda3/lib/python3.8/site-packages (from packaging>=20.9->huggingface-hub->open_clip_torch) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests->huggingface-hub->open_clip_torch) (2022.12.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /root/miniconda3/lib/python3.8/site-packages (from requests->huggingface-hub->open_clip_torch) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.8/site-packages (from requests->huggingface-hub->open_clip_torch) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests->huggingface-hub->open_clip_torch) (2.10)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/lib/python3.8/site-packages (from torchvision->open_clip_torch) (1.22.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /root/miniconda3/lib/python3.8/site-packages (from torchvision->open_clip_torch) (9.1.1)\n",
      "Installing collected packages: fsspec, filelock, huggingface-hub, timm, sentencepiece, regex, ftfy, open-clip-torch\n",
      "Successfully installed filelock-3.12.0 fsspec-2023.4.0 ftfy-6.1.1 huggingface-hub-0.14.1 open-clip-torch-2.19.0 regex-2023.5.5 sentencepiece-0.1.99 timm-0.6.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install open_clip_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ba7d19",
   "metadata": {},
   "source": [
    "# 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e4a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_path_1 = \"/root/autodl-tmp/open_clip-G/open_clip/logs/2023_05_06-19_22_01-model_ViT-bigG-14-lr_4e-07-b_25-j_15-p_amp/checkpoints/epoch_15.pt\"\n",
    "pt_path_2 =\"/root/autodl-tmp/open_clip-G/open_clip/logs/2023_05_06-19_22_01-model_ViT-bigG-14-lr_4e-07-b_25-j_15-p_amp/checkpoints/epoch_10.pt\"\n",
    "pt_path_3 =\"/root/autodl-tmp/open_clip-G/open_clip/logs/2023_05_06-00_03_19-model_ViT-bigG-14-lr_4e-07-b_25-j_15-p_amp/checkpoints/epoch_5.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5da04aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('ViT-bigG-14',\n",
    "                                                                    pretrained = pt_path_1, \n",
    "                                                                     device=device)\n",
    "model_1.output_dict=True\n",
    "\n",
    "model_2, _, image_preprocess = open_clip.create_model_and_transforms('ViT-bigG-14', \n",
    "                                                                     pretrained = pt_path_2, \n",
    "                                                                     device=device)\n",
    "model_2.output_dict=True\n",
    "\n",
    "model_3, _, image_preprocess = open_clip.create_model_and_transforms('ViT-bigG-14', \n",
    "                                                                     pretrained = pt_path_3, \n",
    "                                                                     device=device)\n",
    "model_3.output_dict=True\n",
    "\n",
    "# model_4, _, image_preprocess = open_clip.create_model_and_transforms('ViT-L-14', \n",
    "#                                                                      pretrained = pt_path_4, \n",
    "#                                                                      device=device)\n",
    "# model_4.output_dict=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f76ece",
   "metadata": {},
   "source": [
    "# Uniform Model Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27e3758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [model_1, model_2,model_3 ,model_4]\n",
    "models = [model_1, model_2,model_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bc3f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义目标模型\n",
    "target_model = model_1\n",
    "\n",
    "# 创建一个 AveragedModel 对象，它将包装目标模型并维护一个平均参数向量\n",
    "swa_model = AveragedModel(target_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5435142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对每个输入模型，更新 swa_model 的平均参数向量\n",
    "for model in models:\n",
    "    swa_model.update_parameters(model)\n",
    "\n",
    "# 将 swa_model 的平均参数向量复制到目标模型中\n",
    "# swa_model.swap_parameters(target_model)\n",
    "target_model = swa_model.module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfba9c44",
   "metadata": {},
   "source": [
    "# Greedy Model Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dafdfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from training.data import get_data\n",
    "from training.params import parse_args\n",
    "from open_clip import create_model_and_transforms, trace_model, get_tokenizer, create_loss\n",
    "import sys\n",
    "import params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6631871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.train import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d41c19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = params.parse_args([])\n",
    "args.train_data =  'data/train_data.csv'\n",
    "args.val_data =  'data/val_data.csv'\n",
    "args.dataset_type = 'csv'\n",
    "args.csv_separator =  \"\\\\t\"\n",
    "args.csv_img_key = 'filepath'\n",
    "args.csv_caption_key = 'title'\n",
    "args.distributed = False\n",
    "args.device = device\n",
    "args.rank = 0\n",
    "args.save_logs = False\n",
    "args.wandb = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7df034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(args, (preprocess_train, preprocess_val), epoch=0, tokenizer=get_tokenizer(args.model))\n",
    "assert len(data), 'At least one train or eval dataset must be specified.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b476a17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd0771389e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yyg/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/yyg/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/yyg/anaconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd0771389e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yyg/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/yyg/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/yyg/anaconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_to_text_mean_rank': 31.393495458540873,\n",
       " 'image_to_text_median_rank': 6.0,\n",
       " 'image_to_text_R@1': 0.12833284500439496,\n",
       " 'image_to_text_R@5': 0.47055376501611484,\n",
       " 'image_to_text_R@10': 0.6088485203633167,\n",
       " 'text_to_image_mean_rank': 31.848227365953708,\n",
       " 'text_to_image_median_rank': 6.0,\n",
       " 'text_to_image_R@1': 0.1526516261353648,\n",
       " 'text_to_image_R@5': 0.4869616173454439,\n",
       " 'text_to_image_R@10': 0.6182244359800761,\n",
       " 'clip_val_loss': 2.340339422225952,\n",
       " 'epoch': 0,\n",
       " 'num_samples': 3413}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completed_epoch = 0\n",
    "evaluate(model_1, data, completed_epoch, args, tb_writer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a020108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'models_lst':[model_1, model_2,model_3 ,model_4, model_5],\n",
    "    'performances_lst':[]\n",
    "}\n",
    "for model in models['models_lst']:\n",
    "    metric = evaluate(model, data, completed_epoch, args, tb_writer=None)\n",
    "    models['performances_lst'].append(metric[\"text_to_image_R@10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da89ce41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models['models_lst'] = sorted(models['models_lst'], key=lambda x:models['performances_lst'][models['models_lst'].index(x)], reverse=True)\n",
    "models['performances_lst'] = sorted(models['performances_lst'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf0a7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = models['models_lst'][0]\n",
    "swa_model = AveragedModel(target_model)\n",
    "best_acc = models['performances_lst'][0]\n",
    "for idx, model in enumerate(models['models_lst']):\n",
    "    hsty_model = swa_model.module #备份融合前的模型\n",
    "    swa_model.update_parameters(model)\n",
    "    metric = evaluate(swa_model.module, data, completed_epoch, args, tb_writer=None)\n",
    "    if metric[\"text_to_image_R@10\"] > best_acc: #如果性能提升了，更新目标模型，保留融合后的模型\n",
    "        best_acc = metric[\"text_to_image_R@10\"]\n",
    "        target_model = swa_model.module\n",
    "    else:\n",
    "        swa_model = AveragedModel(hsty_model) #如果性能下降了，不更新目标模型，退回融合前的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0615d754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6642250219748023\n"
     ]
    }
   ],
   "source": [
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71164a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6642250219748023, 0.6607090536185174, 0.6484031643715207, 0.6182244359800761, 0.35071784353940816]\n"
     ]
    }
   ],
   "source": [
    "print(models['performances_lst'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ead5c5b",
   "metadata": {},
   "source": [
    "# Save Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94371ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "086e5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/root/autodl-tmp/open_clip-G/open_clip/logs/2023_05_06-19_22_01-model_ViT-bigG-14-lr_4e-07-b_25-j_15-p_amp/checkpoints/epoch_t.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a9c428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dict = {\n",
    "        \"epoch\": 10,\n",
    "        \"name\": \"soup\",\n",
    "        \"state_dict\": target_model.state_dict(),\n",
    "        \"optimizer\": None#optimizer.state_dict(),\n",
    "    }\n",
    "\n",
    "torch.save(\n",
    "        checkpoint_dict,model_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b0924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
